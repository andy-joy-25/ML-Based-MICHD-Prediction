{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_data_preprocessing import all_permutations, build_poly, random_undersampling\n",
    "from helper_inference import test_evaluation\n",
    "from helper_metrics import compute_metrics, compute_confusion_matrix, threshold_plot\n",
    "from helpers_submission import load_data, append_row, create_file\n",
    "from helper_training import best_parameters_selection\n",
    "from experiments import ensemble_logistic_regression_experiment, reg_logistic_regression_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "np.random.seed(42) # Global Seed\n",
    "DATA_PATH = r\"../ML_course/projects/project1/data/new_dataset/\"\n",
    "CV_FOLDS = 3\n",
    "DATAS = [\"train_raw.npy\", \"train_data_full.npy\", \"train_lasso.npy\", \"train_data_subset.npy\", \"train_data_curated.npy\"]\n",
    "FILENAME = \"SECOND_TUNING.csv\"\n",
    "\n",
    "# Params for large logistic regression class\n",
    "# FIRST ROUND\n",
    "PARAMS1 = [\n",
    "    [1.0, 0.1, 0.01, 0.,], # lambdas1 for ridge # 100 is too high\n",
    "    [5., 1.0, 0.1, 0., ], #lambda2 for lasso\n",
    "    [1000], # max_iters\n",
    "    [0.05,], # gamma\n",
    "    [1_028], # batchsize\n",
    "    [False], # plotting\n",
    "    [False], # add a log transform - must be False as we have -1 still in the data    \n",
    "    [1, 3, 5], # degree, must always be second to last!!\n",
    "    [(4, 2), (3, 3), (1, 2), (2, 2), (3, 2), (2, 3), ], # majority_to_minority_ratio, minority oversampling (0 = no sampling), must always be last!!\n",
    "    [0.5], # classification threshold\n",
    "]\n",
    "\n",
    "PARAMS2 = [\n",
    "    [1.0, 0.1, 0.01, 0.,], # lambdas1 for ridge # 100 is too high\n",
    "    [5., 1.0, 0.1, 0., ], #lambda2 for lasso\n",
    "    [1000], # max_iters\n",
    "    [0.05,], # gamma\n",
    "    [1_028], # batchsize\n",
    "    [False], # plotting\n",
    "    [True], # add a log transform - must be False as we have -1 still in the data    \n",
    "    [1, 3, 5], # degree, must always be second to last!!\n",
    "    [(4, 2), (3, 3), (1, 2), (2, 2), (3, 2), (2, 3), ], # majority_to_minority_ratio, minority oversampling (0 = no sampling), must always be last!!\n",
    "    [0.5], # classification threshold\n",
    "]\n",
    "\n",
    "# SECOND ROUND\n",
    "FINER_SEARCH_1 = [\n",
    "    [0.5, 0.1, 0.05, 0.01,], # lambdas1 for ridge\n",
    "    [0.5, 0.1, 0.05, 0.01,], #lambda2 for lasso\n",
    "    [1000], # max_iters\n",
    "    [0.05,], # gamma\n",
    "    [1_028], # batchsize\n",
    "    [False], # plotting    \n",
    "    [False], # add a log transform - must be False as we have -1 still in the data   \n",
    "    [2, 3, 4, 5, 6], # degree, must always be second to last!!\n",
    "    [(3, 2),(3, 3),], # majority_to_minority_ratio undersampling (0 = no sampling), must always be last!!\n",
    "    [0.5, ], # classification threshold\n",
    "]\n",
    "\n",
    "FINER_SEARCH_2 = [\n",
    "    [0.5, 0.1, 0.05, 0.01,], # lambdas1 for ridge\n",
    "    [0.5, 0.1, 0.05, 0.01,], #lambda2 for lasso\n",
    "    [1000], # max_iters\n",
    "    [0.05,], # gamma\n",
    "    [1_028], # batchsize\n",
    "    [False], # plotting    \n",
    "    [True], # add a log transform - must be False as we have -1 still in the data   \n",
    "    [2, 3, 4, 5, 6], # degree, must always be second to last!!\n",
    "    [(3, 2),(3, 3),], # majority_to_minority_ratio undersampling (0 = no sampling), must always be last!!\n",
    "    [0.5, ], # classification threshold\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    ####### Define Experiments ######\n",
    "    exp1 = (\"Logistic Regression with both regularization\", reg_logistic_regression_experiment, all_permutations(FINER_SEARCH_1))\n",
    "    exp2 = (\"Logistic Regression with both regularization\", reg_logistic_regression_experiment, all_permutations(FINER_SEARCH_2))\n",
    "    EXPERIMENTS = [exp1, exp2]\n",
    "    create_file(FILENAME)\n",
    "\n",
    "    for path in DATAS:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = load_data(DATA_PATH, path)\n",
    "        print(\"Dataset has shape: {}\".format(X_train.shape))\n",
    "        METRICS = [\"Test Accuracy\", \"train Accuracy\", \"Test Loss\", \"Train Loss\", \"Test F1\", \"Train F1\"]\n",
    "        #print(X_train.shape)\n",
    "        # Conduct Experiments\n",
    "        for name, model, params in EXPERIMENTS:\n",
    "            #print(\"-\"*15, name, \"-\"*15)\n",
    "            try:\n",
    "                metrics, metrics_std = best_parameters_selection(model, X_train, y_train, CV_FOLDS, params, seed = 1)\n",
    "                #print(\"Finished tuning {}\".format(name))\n",
    "                print(metrics)\n",
    "                #print(params)\n",
    "                for row, row_std, params in zip(metrics, metrics_std, params):\n",
    "\n",
    "                    # append experiment results to csv file\n",
    "                    append_row(FILENAME, name, params, row, data=path)\n",
    "\n",
    "                    # also print the results here\n",
    "                    for name_m, val, std in zip(METRICS, row, row_std):\n",
    "                        print(\"{:>40}: {} ({})\".format(name_m, round(val, 5), round(std, 3)))\n",
    "            except Exception as e:\n",
    "                print(\"An Error occured for {}\".format(name))\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute Current Best Models after First Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"train_data_full.npy\"\n",
    "params = [1.0, 1.0, 1000, 0.05, 1028, True, False, 4, (3, 2), 0.5] # 3,2 is best\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path) # 43.127 to beat\n",
    "\n",
    "test_evaluation(X_train, y_train, X_test, y_test, reg_logistic_regression_experiment, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"train_data_curated.npy\"\n",
    "params = [0.1, 0.1, 1000, 0.05, 1028, True, False, 4, (3, 3), 0.5] # 3,2 is best\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path) # 43.188 to beat\n",
    "\n",
    "test_evaluation(X_train, y_train, X_test, y_test, reg_logistic_regression_experiment, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Best Models after Second Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "path = \"train_data_full.npy\"\n",
    "params = [0.05, 0.5, 1000, 0.05, 1028, True, True, 2, (3, 2), 0.5] # 3,2 is best\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path) # 43.429 to beat\n",
    "\n",
    "test_evaluation(X_train, y_train, X_test, y_test, reg_logistic_regression_experiment, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Ensemble Model (0.4369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best params, 10 times but with bootrapping the data\n",
    "path = \"train_data_full.npy\"\n",
    "params = [0.05, 0.5, 1000, 0.05, 1028, False, True, 2, (3, 2)] # 3,2 is best\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path) # 43.55 to beat with bootstrapping 0.8, 0.4 slightly better even (0.4369), 0.4 is the best\n",
    "threshold = 0.5\n",
    "ensemble_params = [params]*10 # 10 times the best model\n",
    "# test 00.4, and test median ensemble as well- \n",
    "avg_pred_te, ensemble_opt_w, avg_loss_tr, avg_loss_te, _, ensemble_pred_te, median_votes = ensemble_logistic_regression_experiment(y_train, y_test, X_train, X_test, ensemble_params, row_subsample=0.4, col_subsample=1)\n",
    "\n",
    "random_y = np.zeros(y_train.shape)\n",
    "print(\"Averaging\")\n",
    "acc_te, acc_tr, f1_te, f1_tr = compute_metrics(y_test, ensemble_pred_te, y_train, random_y, threshold)\n",
    "print(\"F1_Test: {}\".format(f1_te))\n",
    "print(\"Median Voting\")\n",
    "acc_te, acc_tr, f1_te, f1_tr = compute_metrics(y_test, median_votes, y_train, random_y, threshold)\n",
    "print(\"F1_Test: {}\".format(f1_te))\n",
    "\n",
    "compute_confusion_matrix(y_test, ensemble_pred_te, threshold)\n",
    "threshold_plot(ensemble_pred_te, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best params 5 models in ensemble\n",
    "path = \"train_data_full.npy\"\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path) # 43.33 - worse than just taking the best one\n",
    "threshold = 0.5\n",
    "# Top 5 parameters\n",
    "ensemble_params = [[0.05, 0.5, 1000, 0.05, 1028, False, True, 2, (3, 2)],\n",
    "                    [0.01, 0.5, 1000, 0.05, 1028, False, True, 2, (3, 2)],\n",
    "                    [0.5, 0.5, 1000, 0.05, 1028, False, True, 2, (3, 3)],\n",
    "                    [0.1, 0.1, 1000, 0.05, 1028, False, False, 2, (3, 3)],\n",
    "                    [0.01, 0.1, 1000, 0.05, 1028, False, False, 2, (3, 3)]]\n",
    "ensemble_params = ensemble_params*2 # every model twice \n",
    "\n",
    "avg_pred_te, ensemble_opt_w, avg_loss_tr, avg_loss_te, _, ensemble_pred_te, median_votes = ensemble_logistic_regression_experiment(y_train, y_test, X_train, X_test, ensemble_params, row_subsample=0.8, col_subsample=1)\n",
    "\n",
    "random_y = np.zeros(y_train.shape)\n",
    "print(\"Averaging\")\n",
    "acc_te, acc_tr, f1_te, f1_tr = compute_metrics(y_test, ensemble_pred_te, y_train, random_y, threshold)\n",
    "print(\"F1_Test: {}\".format(f1_te))\n",
    "print(\"Median Voting\")\n",
    "acc_te, acc_tr, f1_te, f1_tr = compute_metrics(y_test, median_votes, y_train, random_y, threshold)\n",
    "print(\"F1_Test: {}\".format(f1_te))\n",
    "compute_confusion_matrix(y_test, ensemble_pred_te, threshold)\n",
    "threshold_plot(ensemble_pred_te, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Classification Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"train_data_full.npy\"\n",
    "params = [0.05, 0.5, 1000, 0.05, 1028, True, True, 2, (3, 2), 0.5]\n",
    "X_train, X_test, y_train, y_test = load_data(DATA_PATH, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_evaluation(X_train, y_train, X_test, y_test, model, model_parameters):\n",
    "    \n",
    "    # extract data modification parameters\n",
    "    model_parameters.pop()\n",
    "    majority_to_minority_ratio, minority_multiplier = model_parameters[-1]\n",
    "    degree = model_parameters[-2]\n",
    "    log_transform = model_parameters[-3]\n",
    "\n",
    "    # only access model_parameters \n",
    "    parameters = model_parameters[:-3]\n",
    "    \n",
    "    # upsample if needed\n",
    "    if majority_to_minority_ratio != 0:\n",
    "        X_train, y_train = random_undersampling(X_train, y_train, majority_to_minority_ratio, minority_multiplier)\n",
    "    \n",
    "    log_x_tr = np.log(X_train+1)\n",
    "    log_x_te= np.log(X_test+1)\n",
    "\n",
    "    # build polynomial feature matrix\n",
    "    X_train = build_poly(X_train, degree)\n",
    "    X_test = build_poly(X_test, degree)\n",
    "\n",
    "    # TODO: add log transform\n",
    "    if log_transform:\n",
    "        X_train = np.column_stack((X_train, log_x_tr))\n",
    "        X_test = np.column_stack((X_test, log_x_te))\n",
    "\n",
    "    # train the model\n",
    "    _, _, _, pred_tr, pred_te = model(y_train, y_test, X_train, X_test, *parameters)\n",
    "\n",
    "    pred_tr = pred_tr[:,0]\n",
    "    pred_te = pred_te[:,0]\n",
    "\n",
    "    f_score = []\n",
    "    classification_thresholds = np.linspace(0, 1, 100)\n",
    "    for classification_threshold in classification_thresholds:\n",
    "        metrics = compute_metrics(y_test, pred_te, y_train, pred_tr, classification_threshold)\n",
    "        f_score.append(metrics[2])  # metrics[2] -> test f-score\n",
    "\n",
    "    # Create a line plot to visualize how F1 score changes with different thresholds\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(classification_thresholds, f_score, marker='o')\n",
    "    plt.xlabel('Classification Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score vs. Classification Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_evaluation(X_train, y_train, X_test, y_test, reg_logistic_regression_experiment, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
